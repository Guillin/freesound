{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">v0.1 This code implements a simple feature extraction and train using Lightgbm.\n",
    "\n",
    "Feature extraction is very simple and can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_label(rows_labels):\n",
    "    \n",
    "    row_labels_list = []\n",
    "    for row in rows_labels:\n",
    "        row_labels = row.split(',')\n",
    "        labels_array = np.zeros((80))\n",
    "        \n",
    "        for label in row_labels:\n",
    "            index = label_mapping[label]\n",
    "            labels_array[index] = 1\n",
    "        \n",
    "        row_labels_list.append(labels_array)\n",
    "    \n",
    "    return row_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features( pathname ):\n",
    "\n",
    "    y, sr = librosa.load( pathname)\n",
    "    # trim silence\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "    xc = pd.Series(y)\n",
    "    \n",
    "    X = []\n",
    "    X.append(len(xc)/sr)\n",
    "    X.append( xc.mean() )\n",
    "    X.append( xc.median() )\n",
    "    X.append( xc.std() )\n",
    "    X.append( xc.max() )\n",
    "    X.append( xc.min() )\n",
    "    X.append( xc.skew() )\n",
    "    X.append( xc.mad() )\n",
    "    X.append( xc.kurtosis() )\n",
    "    \n",
    "    X.append( np.mean(np.diff(xc)) )\n",
    "    X.append( np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0]) )\n",
    "    X.append( np.abs(xc).max() )\n",
    "    X.append( np.abs(xc).min() )\n",
    "    \n",
    "    X.append( xc[:4410].std() )\n",
    "    X.append( xc[-4410:].std() )\n",
    "    X.append( xc[:44100].std() )\n",
    "    X.append( xc[-44100:].std() )\n",
    "    \n",
    "    X.append( xc[:4410].mean() )\n",
    "    X.append( xc[-4410:].mean() )\n",
    "    X.append( xc[:44100].mean() )\n",
    "    X.append( xc[-44100:].mean() )\n",
    "    \n",
    "    X.append( xc[:4410].min() )\n",
    "    X.append( xc[-4410:].min() )\n",
    "    X.append( xc[:44100].min() )\n",
    "    X.append( xc[-44100:].min() )\n",
    "    \n",
    "    X.append( xc[:4410].max() )\n",
    "    X.append( xc[-4410:].max() )\n",
    "    X.append( xc[:44100].max() )\n",
    "    X.append( xc[-44100:].max() )\n",
    "    \n",
    "    X.append( xc[:4410].skew() )\n",
    "    X.append( xc[-4410:].skew() )\n",
    "    X.append( xc[:44100].skew() )\n",
    "    X.append( xc[-44100:].skew() )\n",
    "    \n",
    "    X.append( xc.max() / np.abs(xc.min()) )\n",
    "    X.append( xc.max() - np.abs(xc.min()) )\n",
    "    X.append( xc.sum() )\n",
    "    \n",
    "    X.append( np.mean(np.nonzero((np.diff(xc[:4410]) / xc[:4410][:-1]))[0]) )\n",
    "    X.append( np.mean(np.nonzero((np.diff(xc[-4410:]) / xc[-4410:][:-1]))[0]) )\n",
    "    X.append( np.mean(np.nonzero((np.diff(xc[:44100]) / xc[:44100][:-1]))[0]) )\n",
    "    X.append( np.mean(np.nonzero((np.diff(xc[-44100:]) / xc[-44100:][:-1]))[0]) )\n",
    "    \n",
    "    X.append( np.quantile(xc, 0.95) )\n",
    "    X.append( np.quantile(xc, 0.99) )\n",
    "    X.append( np.quantile(xc, 0.10) )\n",
    "    X.append( np.quantile(xc, 0.05) )\n",
    "    \n",
    "    X.append( np.abs(xc).mean() )\n",
    "    X.append( np.abs(xc).std() )\n",
    "             \n",
    "    return np.array( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4970, 2) (1120, 81)\n"
     ]
    }
   ],
   "source": [
    "train_curated = pd.read_csv('../data/raw/train_curated.csv')\n",
    "#train_noisy_labels = pd.read_csv('../data/raw/train')\n",
    "test = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "\n",
    "print(train_curated.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accelerating_and_revving_and_vroom': 0,\n",
       " 'Accordion': 1,\n",
       " 'Acoustic_guitar': 2,\n",
       " 'Applause': 3,\n",
       " 'Bark': 4,\n",
       " 'Bass_drum': 5,\n",
       " 'Bass_guitar': 6,\n",
       " 'Bathtub_(filling_or_washing)': 7,\n",
       " 'Bicycle_bell': 8,\n",
       " 'Burping_and_eructation': 9,\n",
       " 'Bus': 10,\n",
       " 'Buzz': 11,\n",
       " 'Car_passing_by': 12,\n",
       " 'Cheering': 13,\n",
       " 'Chewing_and_mastication': 14,\n",
       " 'Child_speech_and_kid_speaking': 15,\n",
       " 'Chink_and_clink': 16,\n",
       " 'Chirp_and_tweet': 17,\n",
       " 'Church_bell': 18,\n",
       " 'Clapping': 19,\n",
       " 'Computer_keyboard': 20,\n",
       " 'Crackle': 21,\n",
       " 'Cricket': 22,\n",
       " 'Crowd': 23,\n",
       " 'Cupboard_open_or_close': 24,\n",
       " 'Cutlery_and_silverware': 25,\n",
       " 'Dishes_and_pots_and_pans': 26,\n",
       " 'Drawer_open_or_close': 27,\n",
       " 'Drip': 28,\n",
       " 'Electric_guitar': 29,\n",
       " 'Fart': 30,\n",
       " 'Female_singing': 31,\n",
       " 'Female_speech_and_woman_speaking': 32,\n",
       " 'Fill_(with_liquid)': 33,\n",
       " 'Finger_snapping': 34,\n",
       " 'Frying_(food)': 35,\n",
       " 'Gasp': 36,\n",
       " 'Glockenspiel': 37,\n",
       " 'Gong': 38,\n",
       " 'Gurgling': 39,\n",
       " 'Harmonica': 40,\n",
       " 'Hi-hat': 41,\n",
       " 'Hiss': 42,\n",
       " 'Keys_jangling': 43,\n",
       " 'Knock': 44,\n",
       " 'Male_singing': 45,\n",
       " 'Male_speech_and_man_speaking': 46,\n",
       " 'Marimba_and_xylophone': 47,\n",
       " 'Mechanical_fan': 48,\n",
       " 'Meow': 49,\n",
       " 'Microwave_oven': 50,\n",
       " 'Motorcycle': 51,\n",
       " 'Printer': 52,\n",
       " 'Purr': 53,\n",
       " 'Race_car_and_auto_racing': 54,\n",
       " 'Raindrop': 55,\n",
       " 'Run': 56,\n",
       " 'Scissors': 57,\n",
       " 'Screaming': 58,\n",
       " 'Shatter': 59,\n",
       " 'Sigh': 60,\n",
       " 'Sink_(filling_or_washing)': 61,\n",
       " 'Skateboard': 62,\n",
       " 'Slam': 63,\n",
       " 'Sneeze': 64,\n",
       " 'Squeak': 65,\n",
       " 'Stream': 66,\n",
       " 'Strum': 67,\n",
       " 'Tap': 68,\n",
       " 'Tick-tock': 69,\n",
       " 'Toilet_flush': 70,\n",
       " 'Traffic_noise_and_roadway_noise': 71,\n",
       " 'Trickle_and_dribble': 72,\n",
       " 'Walk_and_footsteps': 73,\n",
       " 'Water_tap_and_faucet': 74,\n",
       " 'Waves_and_surf': 75,\n",
       " 'Whispering': 76,\n",
       " 'Writing': 77,\n",
       " 'Yell': 78,\n",
       " 'Zipper_(clothing)': 79}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_columns = list( test.columns[1:] )\n",
    "label_mapping = dict((label, index) for index, label in enumerate(label_columns))\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_curated_labels = split_and_label(train_curated['labels'])\n",
    "#train_noisy_labels   = split_and_label(train_noisy  ['labels'])\n",
    "len(train_curated_labels)#, len(train_noisy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in label_columns:\n",
    "    train_curated[f] = 0.0\n",
    "    #train_noisy[f] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>...</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "      <th>num_labels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../data/raw/train_curated/0006ae4e.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../data/raw/train_curated/0019ef41.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../data/raw/train_curated/001ec0ad.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../data/raw/train_curated/0026c7cb.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../data/raw/train_curated/0026f116.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels  Accelerating_and_revving_and_vroom  \\\n",
       "0  0006ae4e.wav             Bark                                 0.0   \n",
       "1  0019ef41.wav         Raindrop                                 0.0   \n",
       "2  001ec0ad.wav  Finger_snapping                                 0.0   \n",
       "3  0026c7cb.wav              Run                                 0.0   \n",
       "4  0026f116.wav  Finger_snapping                                 0.0   \n",
       "\n",
       "   Accordion  Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
       "0        0.0              0.0       0.0   1.0        0.0          0.0   \n",
       "1        0.0              0.0       0.0   0.0        0.0          0.0   \n",
       "2        0.0              0.0       0.0   0.0        0.0          0.0   \n",
       "3        0.0              0.0       0.0   0.0        0.0          0.0   \n",
       "4        0.0              0.0       0.0   0.0        0.0          0.0   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  ...  Trickle_and_dribble  Walk_and_footsteps  \\\n",
       "0                           0.0  ...                  0.0                 0.0   \n",
       "1                           0.0  ...                  0.0                 0.0   \n",
       "2                           0.0  ...                  0.0                 0.0   \n",
       "3                           0.0  ...                  0.0                 0.0   \n",
       "4                           0.0  ...                  0.0                 0.0   \n",
       "\n",
       "   Water_tap_and_faucet  Waves_and_surf  Whispering  Writing  Yell  \\\n",
       "0                   0.0             0.0         0.0      0.0   0.0   \n",
       "1                   0.0             0.0         0.0      0.0   0.0   \n",
       "2                   0.0             0.0         0.0      0.0   0.0   \n",
       "3                   0.0             0.0         0.0      0.0   0.0   \n",
       "4                   0.0             0.0         0.0      0.0   0.0   \n",
       "\n",
       "   Zipper_(clothing)  num_labels                                    path  \n",
       "0                0.0         1.0  ../data/raw/train_curated/0006ae4e.wav  \n",
       "1                0.0         1.0  ../data/raw/train_curated/0019ef41.wav  \n",
       "2                0.0         1.0  ../data/raw/train_curated/001ec0ad.wav  \n",
       "3                0.0         1.0  ../data/raw/train_curated/0026c7cb.wav  \n",
       "4                0.0         1.0  ../data/raw/train_curated/0026f116.wav  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_curated[label_columns] = train_curated_labels\n",
    "#train_noisy[label_columns]   = train_noisy_labels\n",
    "\n",
    "train_curated['num_labels'] = train_curated[label_columns].sum(axis=1)\n",
    "#train_noisy['num_labels']   = train_noisy[label_columns].sum(axis=1)\n",
    "\n",
    "train_curated['path'] = '../data/raw/train_curated/'+train_curated['fname']\n",
    "#train_noisy  ['path'] = '../input/train_noisy/'+train_noisy['fname']\n",
    "\n",
    "train_curated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['path'] = '../data/raw/test/' + test['fname']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train = pd.concat([train_curated, train_noisy],axis=0)\n",
    "\n",
    "del train_curated, train_noisy\n",
    "gc.collect()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4970, 84)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_curated\n",
    "del train_curated\n",
    "gc.collect()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making features from train curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4970/4970 [19:56<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = [create_features(fn) for fn in tqdm(train['path'].values)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4970, 46)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/processed/train_curated_features.npy', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making features from test curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1120/1120 [05:27<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "X = [create_features(fn) for fn in tqdm(test['path'].values)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 46)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/processed/test_features.npy', X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "X = Parallel(n_jobs= 4)(delayed(create_features)(fn) for fn in tqdm(train['path'].values) )\n",
    "X = np.array( X )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xtest = Parallel(n_jobs= 4)(delayed(create_features)( '../input/test/'+fn) for fn in tqdm(test['fname'].values) )\n",
    "Xtest = np.array( Xtest )\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=69)\n",
    "\n",
    "params = {'num_leaves': 15,\n",
    "         'min_data_in_leaf': 200, \n",
    "         'objective':'binary',\n",
    "         \"metric\": 'auc',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.05,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_fraction\": 0.85,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"feature_fraction\": 0.20,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": -1,\n",
    "         \"random_state\": 69}\n",
    "\n",
    "PREDTRAIN = np.zeros( (X.shape[0],80) )\n",
    "PREDTEST  = np.zeros( (Xtest.shape[0],80) )\n",
    "for f in range(len(label_columns)):\n",
    "    y = train[ label_columns[f] ].values\n",
    "    oof      = np.zeros( X.shape[0] )\n",
    "    oof_test = np.zeros( Xtest.shape[0] )\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X,y)):\n",
    "        model = lgb.LGBMClassifier(**params, n_estimators = 20000)\n",
    "        model.fit(X[trn_idx,:], \n",
    "                  y[trn_idx], \n",
    "                  eval_set=[(X[val_idx,:], y[val_idx])], \n",
    "                  eval_metric='auc',\n",
    "                  verbose=0, \n",
    "                  early_stopping_rounds=25)\n",
    "        oof[val_idx] = model.predict_proba(X[val_idx,:], num_iteration=model.best_iteration_)[:,1]\n",
    "        oof_test += model.predict_proba(Xtest          , num_iteration=model.best_iteration_)[:,1]/5.0\n",
    "\n",
    "    PREDTRAIN[:,f] = oof    \n",
    "    PREDTEST [:,f] = oof_test\n",
    "    \n",
    "    print( f, str(roc_auc_score( y, oof ))[:6], label_columns[f] )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "    sample_weight = np.sum(truth > 0, axis=1)\n",
    "    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "    overall_lwlrap = label_ranking_average_precision_score(\n",
    "        truth[nonzero_weight_sample_indices, :] > 0, \n",
    "        scores[nonzero_weight_sample_indices, :], \n",
    "        sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "    return overall_lwlrap\n",
    "\n",
    "print( 'lwlrap cv:', calculate_overall_lwlrap_sklearn( train[label_columns].values, PREDTRAIN ) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test[label_columns] = PREDTEST\n",
    "test.to_csv('submission.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_curated.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Signal (env)",
   "language": "python",
   "name": "signalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
