{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core calculation of label precisions for one test sample.\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "  \"\"\"Calculate precisions for each true class for a single sample.\n",
    "  \n",
    "  Args:\n",
    "    scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "    truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "  Returns:\n",
    "    pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "    pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "      classes.\n",
    "  \"\"\"\n",
    "  num_classes = scores.shape[0]\n",
    "  pos_class_indices = np.flatnonzero(truth > 0)\n",
    "  # Only calculate precisions if there are some true classes.\n",
    "  if not len(pos_class_indices):\n",
    "    return pos_class_indices, np.zeros(0)\n",
    "  # Retrieval list of classes for this sample. \n",
    "  retrieved_classes = np.argsort(scores)[::-1]\n",
    "  # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "  class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "  class_rankings[retrieved_classes] = range(num_classes)\n",
    "  # Which of these is a true label?\n",
    "  retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "  retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "  # Num hits for every truncated retrieval list.\n",
    "  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "  precision_at_hits = (\n",
    "      retrieved_cumulative_hits[class_rankings[pos_class_indices]] / \n",
    "      (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "  return pos_class_indices, precision_at_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All-in-one calculation of per-class lwlrap.\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "  \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "  \n",
    "  Arguments:\n",
    "    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "      of presence of that class in that sample.\n",
    "    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "      test's real-valued score for each class for each sample.\n",
    "  \n",
    "  Returns:\n",
    "    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each \n",
    "      class.\n",
    "    weight_per_class: np.array of (num_classes,) giving the prior of each \n",
    "      class within the truth labels.  Then the overall unbalanced lwlrap is \n",
    "      simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "  \"\"\"\n",
    "  assert truth.shape == scores.shape\n",
    "  num_samples, num_classes = scores.shape\n",
    "  # Space to store a distinct precision value for each class on each sample.\n",
    "  # Only the classes that are true for each sample will be filled in.\n",
    "  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "  for sample_num in range(num_samples):\n",
    "    pos_class_indices, precision_at_hits = (\n",
    "      _one_sample_positive_class_precisions(scores[sample_num, :], \n",
    "                                            truth[sample_num, :]))\n",
    "    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "        precision_at_hits)\n",
    "  labels_per_class = np.sum(truth > 0, axis=0)\n",
    "  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "  # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "  # a particular class.\n",
    "  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) / \n",
    "                      np.maximum(1, labels_per_class))\n",
    "  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "  #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "  return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall lwlrap using sklearn.metrics function.\n",
    "\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "  sample_weight = np.sum(truth > 0, axis=1)\n",
    "  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :], \n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "  return overall_lwlrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulator object version.\n",
    "\n",
    "class lwlrap_accumulator(object):\n",
    "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n",
    "\n",
    "  def __init__(self):\n",
    "    self.num_classes = 0\n",
    "    self.total_num_samples = 0\n",
    "  \n",
    "  def accumulate_samples(self, batch_truth, batch_scores):\n",
    "    \"\"\"Cumulate a new batch of samples into the metric.\n",
    "    \n",
    "    Args:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean\n",
    "        ground-truth of presence of that class in that sample for this batch.\n",
    "      scores: np.array of (num_samples, num_classes) giving the \n",
    "        classifier-under-test's real-valued score for each class for each\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    assert batch_scores.shape == batch_truth.shape\n",
    "    num_samples, num_classes = batch_truth.shape\n",
    "    if not self.num_classes:\n",
    "      self.num_classes = num_classes\n",
    "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
    "      self._per_class_cumulative_count = np.zeros(self.num_classes, \n",
    "                                                  dtype=np.int)\n",
    "    assert num_classes == self.num_classes\n",
    "    for truth, scores in zip(batch_truth, batch_scores):\n",
    "      pos_class_indices, precision_at_hits = (\n",
    "        _one_sample_positive_class_precisions(scores, truth))\n",
    "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
    "        precision_at_hits)\n",
    "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
    "    self.total_num_samples += num_samples\n",
    "\n",
    "  def per_class_lwlrap(self):\n",
    "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
    "    return (self._per_class_cumulative_precision / \n",
    "            np.maximum(1, self._per_class_cumulative_count))\n",
    "\n",
    "  def per_class_weight(self):\n",
    "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
    "    return (self._per_class_cumulative_count / \n",
    "            float(np.sum(self._per_class_cumulative_count)))\n",
    "\n",
    "  def overall_lwlrap(self):\n",
    "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
    "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: LOADING DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreeSoundDataset(Dataset):\n",
    "    \"\"\" FreeSound dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X)\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x_data[index], self.y_data[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../data/processed/mel/train_curated_mel128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, : ,:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4970, 128, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../data/processed/train_curated.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_onehot = np.load('../data/processed/y_onehotenc_train_curated.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, labels_onehot, test_size=0.3, random_state=47) #, stratify=target)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = [l.split(',')[0] for l in labels]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target = le.transform(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3479, 128, 128)\n",
      "X_test: (1491, 128, 128)\n",
      "y_train: (3479, 80)\n",
      "y_test: (1491, 80)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "\n",
    "print('X_test:', X_test.shape)\n",
    "\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FreeSoundDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FreeSoundDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: MAKING DATASET ITERABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: CREATE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=200, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(200)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=200, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(100)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # # Max pool 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(100 * 16 * 16, 80) \n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x.float())\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Max pool 2\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolution 3\n",
    "        out = self.cnn3(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        # Max pool 3\n",
    "        out = self.maxpool3(out)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "        # Dropout 1\n",
    "        #out = self.dropout(out)\n",
    "\n",
    "                     \n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: INSTANTIATE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: INSTANTIATE LOSS CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: INSTANTIATE OPTIMIZER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.056154847145080566. Lwlrap from per-class values: 0.5570878957643663.  \\m\n",
      "Iteration: 1000. Loss: 0.025757526978850365. Lwlrap from per-class values: 0.4273558523743946.  \\m\n",
      "Iteration: 1500. Loss: 0.012749080546200275. Lwlrap from per-class values: 0.5275147942766522.  \\m\n",
      "Iteration: 2000. Loss: 0.007612456567585468. Lwlrap from per-class values: 0.4335649649000816.  \\m\n",
      "Iteration: 2500. Loss: 0.0036713574081659317. Lwlrap from per-class values: 0.3982001833600832.  \\m\n",
      "Iteration: 3000. Loss: 0.010304748080670834. Lwlrap from per-class values: 0.5442245960389077.  \\m\n",
      "Iteration: 3500. Loss: 0.003983215894550085. Lwlrap from per-class values: 0.49467021966760094.  \\m\n",
      "Iteration: 4000. Loss: 0.001142236520536244. Lwlrap from per-class values: 0.44478508632053415.  \\m\n",
      "Iteration: 4500. Loss: 0.0019192267209291458. Lwlrap from per-class values: 0.5230767356425251.  \\m\n",
      "Iteration: 5000. Loss: 0.002414099406450987. Lwlrap from per-class values: 0.5048557794780206.  \\m\n",
      "Iteration: 5500. Loss: 0.0021817353554069996. Lwlrap from per-class values: 0.4743547022693001.  \\m\n",
      "Iteration: 6000. Loss: 0.0017625242471694946. Lwlrap from per-class values: 0.3954813843078461.  \\m\n",
      "Iteration: 6500. Loss: 0.00023587147006765008. Lwlrap from per-class values: 0.4724437677635676.  \\m\n",
      "Iteration: 7000. Loss: 0.0001545030390843749. Lwlrap from per-class values: 0.42551050138006663.  \\m\n",
      "Iteration: 7500. Loss: 0.00017180682334583253. Lwlrap from per-class values: 0.4797608931983932.  \\m\n",
      "Iteration: 8000. Loss: 0.0002794443571474403. Lwlrap from per-class values: 0.461108485060691.  \\m\n",
      "Iteration: 8500. Loss: 0.0003238809294998646. Lwlrap from per-class values: 0.46646435298509503.  \\m\n",
      "Iteration: 9000. Loss: 6.3598463384551e-06. Lwlrap from per-class values: 0.4687751120235005.  \\m\n",
      "Iteration: 9500. Loss: 3.3105072361649945e-05. Lwlrap from per-class values: 0.5188076304189388.  \\m\n",
      "Iteration: 10000. Loss: 0.00010721480794018134. Lwlrap from per-class values: 0.4840047016242669.  \\m\n",
      "Iteration: 10500. Loss: 0.0003808307519648224. Lwlrap from per-class values: 0.5205454234083267.  \\m\n"
     ]
    }
   ],
   "source": [
    "niter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.unsqueeze(1).cuda())\n",
    "            labels = Variable(labels.float().cuda())\n",
    "        else:\n",
    "            images = Variable(images.unsqueeze(1))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        #images = images.unsqueeze(1).type(torch.FloatTensor).cuda()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        niter += 1\n",
    "        \n",
    "        if niter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.unsqueeze(1).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.unsqueeze(1))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "            # Get predictions from the maximum value\n",
    "            per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(labels.cpu().detach().numpy() , outputs.cpu().detach().numpy() )\n",
    "            print('Iteration: {}. Loss: {}. Lwlrap from per-class values: {}. '.format(niter, loss.data, np.sum(per_class_lwlrap * weight_per_class)),'\\m')\n",
    "            \n",
    "            #print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(labels.cpu().detach().numpy() , outputs.cpu().detach().numpy()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images,labelt) = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    images = Variable(images.unsqueeze(1).cuda())\n",
    "\n",
    "# Forward pass only to get logits/output\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test data.\n",
    "num_samples = 100\n",
    "num_labels = 20\n",
    "\n",
    "truth = np.random.rand(num_samples, num_labels) > 0.5\n",
    "# Ensure at least some samples with no truth labels.\n",
    "truth[0:1, :] = False\n",
    "\n",
    "scores = np.random.rand(num_samples, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from per-class values= 0.3012275369810512\n",
      "lwlrap from sklearn.metrics = 0.5657088507625565\n"
     ]
    }
   ],
   "source": [
    "per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(labelt.cpu().detach().numpy() , outputs.cpu().detach().numpy() )\n",
    "print(\"lwlrap from per-class values=\", np.sum(per_class_lwlrap * weight_per_class))\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelt.cpu().detach().numpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-130.60008 , -112.29409 ,  -90.02456 , -141.55603 , -146.94965 ,\n",
       "        -92.549416, -186.11739 , -122.21728 ,  -99.73758 , -115.073425,\n",
       "       -134.75891 , -145.89445 , -143.71509 , -141.80373 ,  -81.79933 ,\n",
       "        -86.48598 ,  -73.38045 , -112.507095, -138.28325 , -125.82384 ,\n",
       "        -74.430626,  -82.33194 , -139.56311 ,  -90.3098  ,  -90.489075,\n",
       "       -126.73173 , -107.03858 ,  -74.31243 ,  -93.32175 , -115.7795  ,\n",
       "       -101.50602 , -110.544655, -106.480644, -122.641716,  -31.093416,\n",
       "       -127.77177 , -102.79919 , -125.34312 , -142.04366 ,  -52.844185,\n",
       "       -118.5954  , -128.69861 ,  -94.46507 , -104.3044  ,  -57.981983,\n",
       "       -137.85835 , -125.455154, -123.36449 , -175.41052 ,  -71.872375,\n",
       "       -128.29597 , -134.72775 , -111.067055, -109.17908 , -117.76506 ,\n",
       "       -102.995125, -101.37364 ,  -53.953674, -114.60611 ,  -45.361805,\n",
       "        -95.50747 ,  -61.794506,  -89.208626, -115.70798 ,  -84.11334 ,\n",
       "       -103.25519 , -171.5958  , -138.87572 ,  -83.03413 ,  -88.04767 ,\n",
       "        -49.211258, -213.50911 ,  -75.48269 , -138.88548 ,  -88.64785 ,\n",
       "       -163.95622 , -116.43493 ,  -65.65678 ,  -87.110435,  -51.036236],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.cpu().detach().numpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test data.\n",
    "num_samples = 100\n",
    "num_labels = 20\n",
    "\n",
    "truth = np.random.rand(num_samples, num_labels) > 0.5\n",
    "# Ensure at least some samples with no truth labels.\n",
    "truth[0:1, :] = False\n",
    "\n",
    "scores = np.random.rand(num_samples, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from per-class values= 0.6202861540585706\n",
      "lwlrap from sklearn.metrics = 0.6202861540585706\n"
     ]
    }
   ],
   "source": [
    "per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(truth, scores)\n",
    "print(\"lwlrap from per-class values=\", np.sum(per_class_lwlrap * weight_per_class))\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.62235368, 0.60364528, 0.59153904, 0.6855551 , 0.62823323,\n",
       "        0.56799037, 0.60324937, 0.63270653, 0.62807842, 0.60554864,\n",
       "        0.64809972, 0.59708764, 0.66036523, 0.64441004, 0.62345638,\n",
       "        0.60308589, 0.59904848, 0.63103118, 0.62637609, 0.62262411]),\n",
       " array([0.05163853, 0.040715  , 0.04865938, 0.04568024, 0.05064548,\n",
       "        0.05263158, 0.05759682, 0.05263158, 0.05163853, 0.04865938,\n",
       "        0.04270109, 0.05461768, 0.04270109, 0.05163853, 0.04468719,\n",
       "        0.05064548, 0.05660377, 0.05660377, 0.05163853, 0.04766634]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_lwlrap, weight_per_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 20), (100, 20))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, truth.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = Variable(torch.randn(1, 1, 65, 65))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxpool = nn.MaxPool2d(kernel_size=2 )#, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = maxpool(a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = cnn2(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = maxpool(c)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=[[0,0,1,1,1,1,2,2,2],\n",
    "   [1,1,1,1,1,1,2,2,2],\n",
    " [2,2,2,2,3,3,3,3,3]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = preprocessing.scale(a, axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = preprocessing.scale(a, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (base env)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
